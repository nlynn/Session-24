{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f48608-1af9-4184-86c4-3df941b733af",
   "metadata": {},
   "source": [
    "# Fun with CCDs\n",
    "\n",
    "**LSST-DA Data Science Fellowship Program**\n",
    "\n",
    "*by Alex Drlica-Wagner*\n",
    "\n",
    "\n",
    "This set of exercises is intended to get you familiar with some of the intricacies of working with images from CCDs. This may be the only time you touch raw LSST images (well, actually DP1 images from LSSTComCam, but close enough). The goal is to get a sense for the \"warts and pimples\" in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd6e5d-c1bc-4ec6-b4e0-bd58e8c9ece4",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "This section goes through how to access a raw image from the butler. You don't need to know what is going on under the hood here, just think of this as a way to access a non-local file server. **If you don't have access to the [Rubin Science Platform](https://data.lsst.cloud/), please contact the instructor!**\n",
    "\n",
    "If at some point you are interested in more details about accessing the raw images, you can check out the associated tutorial notebook: [202.5. Raw images](https://dp1.lsst.io/tutorials/notebook/202/notebook-202-5.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6048f205-7217-4ed2-bc26-6aa5295f5b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lsst'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# LSST Science Pipelines (Stack) packages\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlsst\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdaf\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbutler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdafButler\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlsst\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mafw\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mafwDisplay\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# The DP1 data lives in a butler collection.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'lsst'"
     ]
    }
   ],
   "source": [
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.afw.display as afwDisplay\n",
    "\n",
    "# The DP1 data lives in a butler collection.\n",
    "config = 'dp1'\n",
    "collections = \"LSSTComCam/DP1\"\n",
    "butler = dafButler.Butler(config, collections=collections)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce15236c-3293-46d3-a5fa-117c80392260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T04:21:12.562066Z",
     "iopub.status.busy": "2025-09-14T04:21:12.561837Z",
     "iopub.status.idle": "2025-09-14T04:21:14.280060Z",
     "shell.execute_reply": "2025-09-14T04:21:14.279337Z",
     "shell.execute_reply.started": "2025-09-14T04:21:12.562048Z"
    }
   },
   "source": [
    "# If we don't know what raw data exists, we can print a few dataRefs...\n",
    "refs = butler.query_datasets('raw')\n",
    "for ref in refs[:10]:\n",
    "    print(ref.dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07320906-1e3f-4686-b6c2-937d64993e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We choose the CCD image that we want to grab.\n",
    "# The LSSTComCam focal plane contains 9 CCDs\n",
    "dataId = {'instrument': 'LSSTComCam', 'detector': 1, 'exposure': 2024120200065, 'band': 'g'}\n",
    "#dataId = {'instrument': 'LSSTComCam', 'detector': 1, 'exposure': 2024120200066, 'band': 'g'}\n",
    "print(dataId)\n",
    "\n",
    "# Now we get the raw image, which is an ExposureF object\n",
    "print(\"Getting raw...\")\n",
    "raw = butler.get('raw', dataId)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af497d43-8cb4-4d69-91f5-b6b21811d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can save the image to a FITS file.\n",
    "outfile = f\"{dataId['instrument']}_{dataId['exposure']}_{dataId['detector']:03d}_{dataId['band']}_raw.fits\"\n",
    "print(outfile)\n",
    "print(f\"Writing {outfile}...\")\n",
    "raw.writeFits(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a2e5b4-7c5d-4e18-871f-82e93f79ac24",
   "metadata": {},
   "source": [
    "## Exercise 1. Exploring the Image\n",
    "\n",
    "The following exercises asks you to visualize and explore the pixel information in the raw image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47517e14-00b0-4263-bdfa-f5ca9e5ffd2b",
   "metadata": {},
   "source": [
    "### Visualize the image\n",
    "\n",
    "**Option 1:** If you are familiar with the standard FITS image viewer tool [SAOImageDS9](https://sites.google.com/cfa.harvard.edu/saoimageds9) (commonly known as `ds9`), then probably the easiest way to view the image is to download it and view it with ds9 locally. If you don't have `ds9` on your machine, you can download it for most systems using the link above.\n",
    "\n",
    "* Execute the cells above to save the image to a FITS file.\n",
    "* Download the FITS file by right clicking on the icon associated with the file in the File Browser (to the left of this notebook) and select \"Download.\n",
    "* Open the FITS file with ds9. You can do this from the ds9 GUI menu with \"File\" -> \"Open\", or from the command line with:\n",
    "\n",
    "```\n",
    "ds9 LSSTComCam_2024120200065_001_g_raw.fits\n",
    "```\n",
    "\n",
    "**Option 2:** You can view the image interactively using the Firefly visualization interface. To do this, execute the following code in a cell. This should open a new notebook tab with a firefly frame and that displays the raw image.\n",
    "\n",
    "```\n",
    "afwDisplay.setDefaultBackend('firefly')\n",
    "afw_display = afwDisplay.Display(frame=1)\n",
    "afw_display.image(raw.image)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b36b83-a185-4567-b0aa-739a52c619b8",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> How many distinct sections (amplifiers) are the LSST CCDs divided into?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a96d0-29a5-4892-b36f-7f75470b1d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-14T05:26:48.384929Z",
     "iopub.status.busy": "2025-09-14T05:26:48.384363Z",
     "iopub.status.idle": "2025-09-14T05:26:48.390356Z",
     "shell.execute_reply": "2025-09-14T05:26:48.389588Z",
     "shell.execute_reply.started": "2025-09-14T05:26:48.384901Z"
    }
   },
   "source": [
    "<span style=\"color:red\">Your answer here...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887df8d1-606e-4c12-b7d3-0446ac89e84a",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Why is it difficult to visualize all the sections at a single dynamic range?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbf2e7-78e0-4aba-af28-96c29f2dc07e",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Your answer here...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98d445-4431-45a3-8819-61c0a72a7d04",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> What are the darker regions separating each section of the image? Are there any astronomical objects located in these regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d57183-fa19-4336-832d-828847659814",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Your answer here...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad06648-d1a7-4ed5-ba36-79aed40aac23",
   "metadata": {},
   "source": [
    "### Identify artifacts\n",
    "\n",
    "The next set of questions asks you to identify examples of several different artifacts in the image. Feel free to use Google/ChatGPT to find examples of each of these artifacts.\n",
    "\n",
    "* **Saturation**: when the amount of charge in a pixel exceeds the maximum amount that can be confined to the pixel (i.e., the \"full well\").\n",
    "* **Bleed trail**: electrons from a super-saturated source that start to \"bleed\" away from that source.\n",
    "* **Crosstalk**: electronic signals from a bright \"agressor\" in one amplifier that can be seen in pixels of \"victim\" amplifiers that were read out at the same time.\n",
    "* **Cosmic ray**: energetic charged particle that has penetrated the CCD and left an ionization trail\n",
    "* **Bad pixel(s)**: one or a small group of pixels with an abnormal response.\n",
    "* **Bad column**: a defect in the CCD pixel array that can either be bright (producing excess charge) or dark (trapping charge).\n",
    "* **Bias dip**: the electronic bias level can change within an image introducing apparent dips and features in the background level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859844fa-c73e-4ae4-8cae-5a3999078a67",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Make a copy of the slides you find [here](https://docs.google.com/presentation/d/1E4QCea72qiVExO_G8DiDuLRe-wKOfRL9njHUHDwMsjY). There is one per artifact. Insert a screenshot showing an example of the artifact and complete the associated questions on the slide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528abfc0-8081-45f1-b0b3-632fc3108f10",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Link to your slides here...</span> [link]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daafd00f-f337-4969-a9d4-924d4d8cc290",
   "metadata": {},
   "source": [
    "## Exercise 2. Overscan Bias Correction\n",
    "\n",
    "In this section we are going to isolate the part of the image showing pixels that were exposed to the sky and use the overscan region to correct for the major electronic effects introduced by the amplifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa8cb2-e819-4cf6-b7d8-455dacff90e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default plotting backend to matplotlib\n",
    "afwDisplay.setDefaultBackend('matplotlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3884c4cc-96aa-4ba1-a2f4-9b4806eb7089",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Use matplotlib to plot the full raw image. Play with the `vmin` and `vmax` parameters until you can see astronomical objects in almost every section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52cea6-59f3-4334-8b4c-335a7b90bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw.image.array\n",
    "vmin,vmax=None,None\n",
    "#vmin,vmax = np.percentile(data, [50,50])\n",
    "plt.imshow(data, cmap='gray', origin='lower', norm='log', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e6337-4324-45bc-8602-7d11e5391c2c",
   "metadata": {},
   "source": [
    "Divide the image into amplifier sections. Note that in the above image, the origin (0, 0) is in the lower left corner so the bottom amplifiers have row index 0 and the top amplifiers have row index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb1b21f-65fe-412a-bea0-d3eccfb60d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amplifier sections\n",
    "amp_nrow,amp_ncol = (2,8)\n",
    "ysize = data.shape[0] // amp_nrow\n",
    "xsize = data.shape[1] // amp_ncol\n",
    "amplifiers = dict()\n",
    "for j in range(amp_nrow):\n",
    "    ymin,ymax = j*ysize, j*ysize + ysize\n",
    "    for i in range(amp_ncol):\n",
    "        xmin,xmax = i*xsize, i*xsize + xsize\n",
    "        amplifiers[f'amp{j}{i}'] = data[ymin:ymax,xmin:xmax].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f09ec90-32ed-417c-961c-6cd6c1a2fd26",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Use matplotlib to plot what we are calling \"amplifier 05\" (`amp05` entry in the `amplifiers` dictionary). Set the vmin/vmax values so that you can see stars and galaxies. Answer the following questions:\n",
    "* Where is the serial overscan?\n",
    "* Where is the vertical overscan?\n",
    "* In which corner is the readout amplifier located?\n",
    "* Why are the overscan region much darker than the image of the sky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951ac906-8ab9-4de9-b443-a77c72c5a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust vmin and vmax here.\n",
    "amp = amplifiers['amp05']\n",
    "vmin,vmax = None, None\n",
    "#vmin,vmax = np.percentile(amp, [50,50])\n",
    "plt.imshow(amp,norm='log',cmap='gray', vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4b5bf-c101-432b-9e27-f03be494b5e0",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Plot just the serial overscan and just the parallel overscan regions of amplifier 05 (`amp05`). Do you see more structure in the serial or parallel overscan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a067b57-1a2f-496f-8056-906bdd83afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "#serial_overscan: columns 0 to 65\n",
    "#parallel_overscan: rows 2000 to 2046"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef08163-cd38-47fd-88dc-cd848bc14f0f",
   "metadata": {},
   "source": [
    "<span style=\"color:blue;font-weight: bold;\">Exercise:</span> Calculate the median for each column of the parallel overscan and subtract it from each column of the science image. Does the resulting science image look better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898fe31-b032-4392-9aec-29ee1f493703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the median for each column of the parallel overscan and subtract it from each column of the science image. Does the resulting science image look better?\n",
    "serial_overscan = amp[:, 0:65]\n",
    "parallel_overscan = amp[2000:2046, :]\n",
    "science_image = amp[0:2000, 65:2048]\n",
    "\n",
    "# Calculate the median for each column of the parallel overscan\n",
    "parallel_overscan_median = np.median(parallel_overscan, axis=0)\n",
    "\n",
    "# Subtract the parallel overscan median from each column of the science image\n",
    "corrected_science_image = science_image - parallel_overscan_median\n",
    "plt.imshow(corrected_science_image, norm='log', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf965b8c-a3de-4b89-b67e-5ec11cc3420e",
   "metadata": {},
   "source": [
    "## Extra Credit: Stitch it all back together\n",
    "\n",
    "In this exercise we will use what we learned from the previous examples to subtract the median from the parallel overscan from the science images and stitch everything back together. This can be done pretty efficiently with numpy...\n",
    "\n",
    "* Loop over the amplifiers in row 0. For each amplifier, perform the overscan bias correction. Keep only the on-sky region of the image (i.e., clip off the overscan) and append to an output list.\n",
    "* Use np.hstack to combine the amplifiers in your row 0 output list into a single array.\n",
    "* Do the same procedure for row 1.\n",
    "* Use np.vstack to combine the array for row 0 and row 1.\n",
    "* Plot the resulting image.\n",
    "* Why are there still some dark lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8925ea1-cc54-4746-b537-a34adda618bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSFPpymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
